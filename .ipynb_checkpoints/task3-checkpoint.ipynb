{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4040341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import sys\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caacb998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "Requirement already satisfied: six in c:\\users\\jakinda\\anaconda3\\lib\\site-packages (from langdetect) (1.15.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=1c882b8c6a3b2cf6005887847fba541cb67fd7b74f43f34f7f71452b72d15eb8\n",
      "  Stored in directory: c:\\users\\jakinda\\appdata\\local\\pip\\cache\\wheels\\13\\c7\\b0\\79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5830fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating tweetâ€™s lenght and word count\n",
    "CleanTweets['text_len'] = CleanTweets['clean_text'].astype(str).apply(len)\n",
    "CleanTweets['text_word_count'] = CleanTweets['clean_text'].apply(lambda x: len(str(x).split()))\n",
    "round(pd.DataFrame(CleanTweets.groupby(\"score\").text_len.mean()),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e63e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanTweets.drop(CleanTweets[CleanTweets['score'] =='neutral'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanTweets=CleanTweets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanTweets.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_values_in_column(CleanTweets,\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#series.map({'positive': 1 ,'negative':0})\n",
    "CleanTweets['scoremap']=CleanTweets['score'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanTweets.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = CleanTweets['punct']\n",
    "y = CleanTweets['scoremap']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad3ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "def train_and_show_scores(X: csr_matrix, y: np.array, title: str) -> None:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, train_size=0.75, stratify=y\n",
    "    )\n",
    "    \n",
    "clf = SGDClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "train_score = clf.score(X_train, y_train)\n",
    "valid_score = clf.score(X_valid, y_valid)\n",
    "print(f'{title}\\nTrain score: {round(train_score, 2)} ; Validation score: {round(valid_score, 2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4214cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_vectorizer = CountVectorizer(ngram_range=(3, 3))\n",
    "trigram_vectorizer.fit(X_train.values)\n",
    "\n",
    "dump(trigram_vectorizer, 'data_preprocessors/trigram_vectorizer.joblib')\n",
    "\n",
    "\n",
    "'''\n",
    "count_vect = CountVectorizer(ngram_range=(3, 3))\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trigram = trigram_vectorizer.transform(X_train.values)\n",
    "\n",
    "save_npz('vectorized_data/X_train_trigram.npz', X_train_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126dfb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_tf_idf_transformer = TfidfTransformer()\n",
    "trigram_tf_idf_transformer.fit(X_train_trigram)\n",
    "\n",
    "dump(trigram_tf_idf_transformer, 'data_preprocessors/trigram_tf_idf_transformer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trigram_tf_idf = trigram_tf_idf_transformer.transform(X_train_trigram)\n",
    "\n",
    "save_npz('vectorized_data/X_train_trigram_tf_idf.npz', X_train_trigram_tf_idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598af59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_show_scores(X: csr_matrix, y: np.array, title: str) -> None:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, train_size=0.75, stratify=y\n",
    "    )\n",
    "\n",
    "    clf = SGDClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    valid_score = clf.score(X_valid, y_valid)\n",
    "    print(f'{title}\\nTrain score: {round(train_score, 2)} ; Validation score: {round(valid_score, 2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc26d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcafcb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_show_scores(X_train_trigram, y_train, 'trigram Counts')\n",
    "train_and_show_scores(X_train_trigram_tf_idf, y_train, 'trigram Tf-Idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9b995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.fit(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3cadda",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(y_train)\n",
    "np.mean(predicted == y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
