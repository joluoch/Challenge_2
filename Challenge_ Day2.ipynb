{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDwep1K8Erxl"
   },
   "source": [
    "**Project:** Data Minining Project for  X company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzIu-UWIDXHw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7-ii3uyI8KY"
   },
   "source": [
    "The CRISP-DM Framework\n",
    "\n",
    "\n",
    "The CRISP-DM methodology provides a structured approach to planning a data mining project. It is a robust and well-proven methodology.\n",
    "* Business understanding (BU): Determine Business Objectives, Assess Situation, Determine Data Mining Goals, Produce Project Plan\n",
    "\n",
    "* Data understanding (DU): Collect Initial Data, Describe Data, Explore Data, Verify Data Quality\n",
    "\n",
    "* Data preparation (DP): Select Data, Clean Data, Construct Data, Integrate Data\n",
    "\n",
    "* Modeling (M): Select modeling technique, Generate Test Design, Build Model, Assess Model\n",
    "*  Evaluation (E): Evaluate Results, Review Process, Determine Next Steps\n",
    "*  Deployment (D): Plan Deployment, Plan Monitoring and Maintenance, Produce Final Report, Review Project\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "[What is the CRISP-DM methodology?](https://www.sv-europe.com/crisp-dm-methodology/)\n",
    "\n",
    "[Introduction to CRISP DM Framework for Data Science and Machine Learning](https://www.linkedin.com/pulse/chapter-1-introduction-crisp-dm-framework-data-science-anshul-roy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lo7Ml7tMQOf"
   },
   "source": [
    "**Data Set**\n",
    "### The data is for company X which is trying to control attrition. \n",
    "### There are two sets of data: \"Existing employees\" and \"Employees who have left\". The following attributes are available for every employee.\n",
    "\n",
    "\n",
    "*   Satisfaction Level\n",
    "\n",
    "*   Last evaluation\n",
    "\n",
    "*   Number of projects\n",
    "\n",
    "*   Average monthly hours\n",
    "\n",
    "*   Time spent at the company\n",
    "*   Whether they have had a work accident\n",
    "\n",
    "\n",
    "*  Whether they have had a promotion in the last 5 years\n",
    "\n",
    "\n",
    "*   Departments (column sales)\n",
    "\n",
    "\n",
    "*   Salary\n",
    "\n",
    "\n",
    "*  Whether the employee has left\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjSj2A2sSph_"
   },
   "source": [
    "**Your Role**\n",
    " \n",
    "\n",
    "*   As data science team member X company asked you to answer this two questions.\n",
    "*  What type of employees is leaving? \n",
    "\n",
    "*   Determine which employees are prone to leave next.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajdEVA7LiBUp"
   },
   "source": [
    "Business Understanding\n",
    "\n",
    "---\n",
    "\n",
    "This step mostly focuses on understanding the Business in all the different aspects. It follows the below different steps.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Identify the goal and frame the business problem.\n",
    "* Prepare Analytical Goal i.e. what type of performance metric and loss function to use\n",
    "* Gather information on resource, constraints, assumptions, risks etc\n",
    "* Gather information on resource, constraints, assumptions, risks etc\n",
    "*   Prepare Work Flow Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4MwiCYzj2_u"
   },
   "source": [
    "### Write the main objectives of this project in your words?\n",
    "minimum of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STyLda45j1Mf"
   },
   "outputs": [],
   "source": [
    "main_objectives ='''unticipate who is likely to leave, and what is causing them to leave. This might help keep the good emlployees\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuOlxLxKMOLI"
   },
   "outputs": [],
   "source": [
    "assert len(main_objectives) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(main_objectives) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyXeNxlCkbaw"
   },
   "source": [
    "### Outline the different data analysis steps you will follow to carry out the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rC-tl8sUksQq"
   },
   "outputs": [],
   "source": [
    "dm_outline = '''I will perform EDA, try and find out the similarities and what is unique from this two tables. \n",
    "i would perfom feature selection and plot a box plot\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-K1mWuDoksTk"
   },
   "outputs": [],
   "source": [
    "assert len(dm_outline) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(dm_outline) > 70 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmUDFG1wkzUy"
   },
   "source": [
    "### What metrics will you use to measure the performance of your data analysis model? \n",
    "Write the equations of the metrics here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCNulojKk_BP"
   },
   "source": [
    "e.g. Precision = $\\frac{TP}{(TP + FP)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLS2YHoRk_EK"
   },
   "source": [
    "Why do you choose these metrics? minimum of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSynT14KlPSJ"
   },
   "outputs": [],
   "source": [
    "why_metrics = '''it is known as a confusion metrix and it describes the complete performance of the model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yr-Mk0E8lPVJ"
   },
   "outputs": [],
   "source": [
    "assert len(why_metrics) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(why_metrics) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAo19Ip6lUtm"
   },
   "source": [
    "### How would you know if your data analysis work is a success or not?\n",
    "minimum of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HESsiXW5llX-"
   },
   "outputs": [],
   "source": [
    "how_success = '''I will treat the current employee table as a train set and input a new record to test and\n",
    "the employee who left as the validation table because they have are truely gone.I will calulate the score afterwards \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdUoiMIOlmXq"
   },
   "outputs": [],
   "source": [
    "assert len(how_success) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(how_success) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQE6dqo6l1TZ"
   },
   "source": [
    "## What kind of challenges do you expect in your analysis?\n",
    "List at least 3 challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrAhBQhQl8Lh"
   },
   "outputs": [],
   "source": [
    "challenge_text = '''1.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EedHa-Pll8X7"
   },
   "outputs": [],
   "source": [
    "assert len(challenge_text) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(how_success) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcJ8M6uWDeSE"
   },
   "source": [
    "<h2>Using the processed twitter data from yesterday's challenge</h2>.\n",
    "\n",
    "\n",
    "- Form a new data frame (named `cleanTweet`), containing columns $\\textbf{clean-text}$ and $\\textbf{polarity}$.\n",
    "\n",
    "- Write a function `text_category` that takes a value `p` and returns, depending on the value of p, a string `'positive'`, `'negative'` or `'neutral'`.\n",
    "\n",
    "- Apply this function (`text_category`) on the $\\textbf{polarity}$ column of `cleanTweet` in 1 above to form a new column called $\\textbf{score}$ in `cleanTweet`.\n",
    "\n",
    "- Visualize The $\\textbf{score}$ column using piechart and barchart\n",
    "\n",
    "<h5>Now we want to build a classification model on the clean tweet following the steps below:</h5>\n",
    "\n",
    "* Remove rows from `cleanTweet` where $\\textbf{polarity}$ $= 0$ (i.e where $\\textbf{score}$ = Neutral) and reset the frame index.\n",
    "* Construct a column $\\textbf{scoremap}$ Use the mapping {'positive':1, 'negative':0} on the $\\textbf{score}$ column\n",
    "* Create feature and target variables `(X,y)` from $\\textbf{clean-text}$ and $\\textbf{scoremap}$ columns respectively.\n",
    "* Use `train_test_split` function to construct `(X_train, y_train)` and `(X_test, y_test)` from `(X,y)`\n",
    "\n",
    "* Build an `SGDClassifier` model from the vectorize train text data. Use `CountVectorizer()` with a $\\textit{trigram}$ parameter.\n",
    "\n",
    "* Evaluate your model on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "85WxmGNGDcBY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import tweepy\n",
    "import os\n",
    "import nltk\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "from scipy.sparse import csr_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.corpus import stopwords,WordListCorpusReader\n",
    "from PIL import Image\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement WordListCorpusReader\n",
      "ERROR: No matching distribution found for WordListCorpusReader\n"
     ]
    }
   ],
   "source": [
    "!pip install WordListCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>original_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>lang</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>...</th>\n",
       "      <th>original_author</th>\n",
       "      <th>screen_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>place</th>\n",
       "      <th>place_coord_boundaries</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu Jun 17 06:26:34 +0000 2021</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>Giving forth life is becoming a burden in Keny...</td>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>Sentiment(polarity=0.3194444444444445, subject...</td>\n",
       "      <td>0.3194444444444445</td>\n",
       "      <td>0.5305555555555556</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>reen_law</td>\n",
       "      <td>398</td>\n",
       "      <td>70</td>\n",
       "      <td>223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>janetmachuka_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-06-17 06:26:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Thu Jun 17 06:26:37 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Teenmaar - 26cr\\nPanja - 32.5cr\\nGabbarsingh -...</td>\n",
       "      <td>Teenmaar crPanja crGabbarsingh cr Khaleja Kuda...</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>in</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Amigo9999_</td>\n",
       "      <td>19047</td>\n",
       "      <td>132</td>\n",
       "      <td>1084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maheshblood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "      <td>2021-06-17 06:26:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Thu Jun 17 06:26:42 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Rei chintu 2013 lo Vachina Ad Nizam ne 2018 lo...</td>\n",
       "      <td>Rei chintu lo Vachina Ad Nizam ne lo kottaru f...</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hi</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>MallaSuhaas</td>\n",
       "      <td>47341</td>\n",
       "      <td>2696</td>\n",
       "      <td>2525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hail_Kalyan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vizag</td>\n",
       "      <td>2021-06-17 06:26:42+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Thu Jun 17 06:26:44 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Today is World Day to Combat #Desertification ...</td>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>Sentiment(polarity=0.25, subjectivity=0.65)</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.65</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>CIACOceania</td>\n",
       "      <td>7039</td>\n",
       "      <td>343</td>\n",
       "      <td>387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Desertification, Drought, resilience</td>\n",
       "      <td>EdwardVrkic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>2021-06-17 06:26:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Thu Jun 17 06:26:47 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Hearing #GregHunt say he's confident vaccines ...</td>\n",
       "      <td>Hearing say 's confident vaccines delivered li...</td>\n",
       "      <td>Sentiment(polarity=0.5, subjectivity=0.8333333...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8333333333333334</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>MccarronWendy</td>\n",
       "      <td>26064</td>\n",
       "      <td>419</td>\n",
       "      <td>878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GregHunt, Morrison</td>\n",
       "      <td>WriteWithDave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "      <td>2021-06-17 06:26:47+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      created_at  \\\n",
       "0         0.0  Thu Jun 17 06:26:34 +0000 2021   \n",
       "1         1.0  Thu Jun 17 06:26:37 +0000 2021   \n",
       "2         2.0  Thu Jun 17 06:26:42 +0000 2021   \n",
       "3         3.0  Thu Jun 17 06:26:44 +0000 2021   \n",
       "4         4.0  Thu Jun 17 06:26:47 +0000 2021   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4  <a href=\"http://twitter.com/download/android\" ...   \n",
       "\n",
       "                                       original_text  \\\n",
       "0  Giving forth life is becoming a burden in Keny...   \n",
       "1  Teenmaar - 26cr\\nPanja - 32.5cr\\nGabbarsingh -...   \n",
       "2  Rei chintu 2013 lo Vachina Ad Nizam ne 2018 lo...   \n",
       "3  Today is World Day to Combat #Desertification ...   \n",
       "4  Hearing #GregHunt say he's confident vaccines ...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  Giving forth life becoming burden Kenya This m...   \n",
       "1  Teenmaar crPanja crGabbarsingh cr Khaleja Kuda...   \n",
       "2  Rei chintu lo Vachina Ad Nizam ne lo kottaru f...   \n",
       "3  Today World Day Combat Restoring degraded land...   \n",
       "4  Hearing say 's confident vaccines delivered li...   \n",
       "\n",
       "                                           sentiment            polarity  \\\n",
       "0  Sentiment(polarity=0.3194444444444445, subject...  0.3194444444444445   \n",
       "1          Sentiment(polarity=0.0, subjectivity=0.0)                 0.0   \n",
       "2          Sentiment(polarity=0.0, subjectivity=0.0)                 0.0   \n",
       "3        Sentiment(polarity=0.25, subjectivity=0.65)                0.25   \n",
       "4  Sentiment(polarity=0.5, subjectivity=0.8333333...                 0.5   \n",
       "\n",
       "         subjectivity lang favorite_count  ... original_author screen_count  \\\n",
       "0  0.5305555555555556   en              0  ...        reen_law          398   \n",
       "1                 0.0   in              0  ...      Amigo9999_        19047   \n",
       "2                 0.0   hi              0  ...     MallaSuhaas        47341   \n",
       "3                0.65   en              0  ...     CIACOceania         7039   \n",
       "4  0.8333333333333334   en              0  ...   MccarronWendy        26064   \n",
       "\n",
       "  followers_count friends_count possibly_sensitive  \\\n",
       "0              70           223                NaN   \n",
       "1             132          1084                NaN   \n",
       "2            2696          2525                NaN   \n",
       "3             343           387                NaN   \n",
       "4             419           878                NaN   \n",
       "\n",
       "                               hashtags  user_mentions place  \\\n",
       "0                                   NaN  janetmachuka_   NaN   \n",
       "1                                   NaN    maheshblood   NaN   \n",
       "2                                   NaN    Hail_Kalyan   NaN   \n",
       "3  Desertification, Drought, resilience    EdwardVrkic   NaN   \n",
       "4                    GregHunt, Morrison  WriteWithDave   NaN   \n",
       "\n",
       "    place_coord_boundaries                  timestamp  \n",
       "0                      NaN  2021-06-17 06:26:34+00:00  \n",
       "1                    India  2021-06-17 06:26:37+00:00  \n",
       "2                    Vizag  2021-06-17 06:26:42+00:00  \n",
       "3         Papua New Guinea  2021-06-17 06:26:44+00:00  \n",
       "4  Sydney, New South Wales  2021-06-17 06:26:47+00:00  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('cleaned_fintech_data.csv')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>0.3194444444444445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teenmaar crPanja crGabbarsingh cr Khaleja Kuda...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rei chintu lo Vachina Ad Nizam ne lo kottaru f...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hearing say 's confident vaccines delivered li...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text            polarity\n",
       "0  Giving forth life becoming burden Kenya This m...  0.3194444444444445\n",
       "1  Teenmaar crPanja crGabbarsingh cr Khaleja Kuda...                 0.0\n",
       "2  Rei chintu lo Vachina Ad Nizam ne lo kottaru f...                 0.0\n",
       "3  Today World Day Combat Restoring degraded land...                0.25\n",
       "4  Hearing say 's confident vaccines delivered li...                 0.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweet= [\"clean_text\",\"polarity\"]\n",
    "tweets[clean_tweet].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>0.3194444444444445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teenmaar crPanja crGabbarsingh cr Khaleja Kuda...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rei chintu lo Vachina Ad Nizam ne lo kottaru f...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hearing say 's confident vaccines delivered li...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text            polarity\n",
       "0  Giving forth life becoming burden Kenya This m...  0.3194444444444445\n",
       "1  Teenmaar crPanja crGabbarsingh cr Khaleja Kuda...                 0.0\n",
       "2  Rei chintu lo Vachina Ad Nizam ne lo kottaru f...                 0.0\n",
       "3  Today World Day Combat Restoring degraded land...                0.25\n",
       "4  Hearing say 's confident vaccines delivered li...                 0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleanTweets = tweets[clean_tweet]\n",
    "CleanTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5621\n",
       "unique     246\n",
       "top        0.0\n",
       "freq      2134\n",
       "Name: polarity, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleanTweets[\"polarity\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Calculating Negative, Positive, Neutral and Compound values\n",
    "tw_list[[‘polarity’, ‘subjectivity’]] = tw_list[‘text’].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    "for index, row in tw_list[‘text’].iteritems():\n",
    " score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    " neg = score[‘neg’]\n",
    " neu = score[‘neu’]\n",
    " pos = score[‘pos’]\n",
    " comp = score[‘compound’]\n",
    " if neg > pos:\n",
    " tw_list.loc[index, ‘sentiment’] = “negative”\n",
    " elif pos > neg:\n",
    " tw_list.loc[index, ‘sentiment’] = “positive”\n",
    " else:\n",
    " tw_list.loc[index, ‘sentiment’] = “neutral”\n",
    " tw_list.loc[index, ‘neg’] = neg\n",
    " tw_list.loc[index, ‘neu’] = neu\n",
    " tw_list.loc[index, ‘pos’] = pos\n",
    " tw_list.loc[index, ‘compound’] = comp'''\n",
    "\n",
    "def text_category (p):\n",
    "    if(p > 0):\n",
    "        return \"positive\"\n",
    "    elif(p < 0):\n",
    "        return \"negative\"  \n",
    "    elif(p==0):\n",
    "        return \"neutral\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3486.000000\n",
       "mean        0.162701\n",
       "std         0.270288\n",
       "min        -0.800000\n",
       "25%         0.036364\n",
       "50%         0.154167\n",
       "75%         0.350000\n",
       "max         1.000000\n",
       "Name: polarity, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CleanTweets[\"polarity\"] = pd.to_numeric(CleanTweets[\"polarity\"])\n",
    "#CleanTweets['score'] =CleanTweets['polarity'].apply(text_category)\n",
    "#CleanTweets= CleanTweets.astype({\"polarity\":'float'})\n",
    "#CleanTweets.astype({'polarity': 'float'}).dtypes\n",
    "#CleanTweets['polarity'] = CleanTweets.polarity.astype(float)\n",
    "#CleanTweets[\"polarity\"]= CleanTweets[\"polarity\"].astype(float)\n",
    "#pd.to_numeric(CleanTweets.polarity)\n",
    "CleanTweets[\"polarity\"]=pd.to_numeric(CleanTweets[\"polarity\"], errors='coerce')\n",
    "CleanTweets[\"polarity\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanTweets['score'] = CleanTweets['polarity'].apply(text_category)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teenmaar crPanja crGabbarsingh cr Khaleja Kuda...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rei chintu lo Vachina Ad Nizam ne lo kottaru f...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hearing say 's confident vaccines delivered li...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Credit/Debit yrs kastam .. Top lo kuda compari...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Macam-macam bentuk selaput dara Elastisitas be...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>I n't want meat Australia Besides ghastly anim...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>`` By Mazda assumes quarter products fully ele...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Bari Flops Gale Kotre Inyar Fans Irtare Guru I...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_text  polarity     score\n",
       "0    Giving forth life becoming burden Kenya This m...  0.319444  positive\n",
       "1    Teenmaar crPanja crGabbarsingh cr Khaleja Kuda...  0.000000   neutral\n",
       "2    Rei chintu lo Vachina Ad Nizam ne lo kottaru f...  0.000000   neutral\n",
       "3    Today World Day Combat Restoring degraded land...  0.250000  positive\n",
       "4    Hearing say 's confident vaccines delivered li...  0.500000  positive\n",
       "..                                                 ...       ...       ...\n",
       "995  Credit/Debit yrs kastam .. Top lo kuda compari...  0.500000  positive\n",
       "996  Macam-macam bentuk selaput dara Elastisitas be...  0.500000  positive\n",
       "997  I n't want meat Australia Besides ghastly anim...  0.000000   neutral\n",
       "998  `` By Mazda assumes quarter products fully ele...  0.100000  positive\n",
       "999  Bari Flops Gale Kotre Inyar Fans Irtare Guru I...  0.500000  positive\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleanTweets.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new data frames for all sentiments (positive, negative and neutral)\n",
    "CleanTweets_negative = CleanTweets[CleanTweets[\"score\"]==\"negative\"]\n",
    "CleanTweets_positive = CleanTweets[CleanTweets[\"score\"]==\"positive\"]\n",
    "CleanTweets_neutral = CleanTweets[CleanTweets[\"score\"]==\"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>2648</td>\n",
       "      <td>75.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>838</td>\n",
       "      <td>24.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total  Percentage\n",
       "positive   2648       75.96\n",
       "negative    838       24.04"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_values_in_column(data,feature):\n",
    "    total = data.loc[:,feature].value_counts(dropna=False)\n",
    "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2) \n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n",
    "#Count_values for sentiment\n",
    "count_values_in_column(CleanTweets,\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CleanTweets['score'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='score'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "CleanTweets['score'].value_counts().plot(kind='pie')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-fb8b87e315f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"C:\\Users\\Jakinda\\Documents\\Python Scripts\\challenge2\\challenge2\\cloud.png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "path = r\"C:\\Users\\Jakinda\\Documents\\Python Scripts\\challenge2\\challenge2\\cloud.png\"\n",
    "assert os.path.isfile(path)\n",
    "with open(path, \"r\") as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordcloud(text):\n",
    "    mask = np.array(Image.open())\n",
    "    stopwords = set(STOPWORDS)\n",
    "    wc = WordCloud(background_color=\"white\",\n",
    "    mask = mask,\n",
    "    max_words=3000,\n",
    "    stopwords=stopwords,\n",
    "    repeat=True)\n",
    "    wc.generate(str(text))\n",
    "    wc.to_file(\"wc.png\")\n",
    "    print(\"word cloud saved\")\n",
    "    path=\"wc.png\"\n",
    "    display(Image.open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_wordcloud(msgs):\n",
    "    \"\"\"\n",
    "        Draw wordcloud for visualization of the most used words \n",
    "        during conversation\n",
    "        args: msgs chat content\n",
    "        return: a wordcloud with the most used words having the \n",
    "        highest font value \n",
    "    \"\"\"\n",
    "    allWords = ' '.join([twts for twts in msgs])\n",
    "    wordCloud = WordCloud(width=350, height=170, random_state=21, max_words=190, mode='RGBA',\n",
    "                      max_font_size=150, stopwords=stopwords, scale=9,\n",
    "                        min_word_length=4).generate(allWords)\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.imshow(wordCloud, interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(); plt.title('most used words', size=20)\n",
    "    plt.savefig('masked_wordcloud.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>2648</td>\n",
       "      <td>75.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>838</td>\n",
       "      <td>24.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total  Percentage\n",
       "positive   2648       75.96\n",
       "negative    838       24.04"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CleanTweets.iloc[1743]\n",
    "\n",
    "count_values_in_column(CleanTweets,\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'WordListCorpusReader' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-38c2589e0bb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Creating wordcloud for all tweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdraw_wordcloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCleanTweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-122-a9338ed1803e>\u001b[0m in \u001b[0;36mdraw_wordcloud\u001b[1;34m(msgs)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m      9\u001b[0m     \u001b[0mallWords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtwts\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtwts\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmsgs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     wordCloud = WordCloud(width=350, height=170, random_state=21, max_words=190, mode='RGBA',\n\u001b[0m\u001b[0;32m     11\u001b[0m                       \u001b[0mmax_font_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                         min_word_length=4).generate(allWords)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \"\"\"\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \"\"\"\n\u001b[1;32m--> 613\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    584\u001b[0m             \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_word_length\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollocations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0mword_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munigrams_and_bigrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_plurals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollocation_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'WordListCorpusReader' object is not iterable"
     ]
    }
   ],
   "source": [
    "#Creating wordcloud for all tweets\n",
    "draw_wordcloud(CleanTweets[\"score\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\Jakinda\\\\Documents\\\\Python Scripts\\\\challenge2\\\\challenge2\\\\cloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-20b261f4d484>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Creating wordcloud for positive sentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcreate_wordcloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCleanTweets_positive\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-c65731254284>\u001b[0m in \u001b[0;36mcreate_wordcloud\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_wordcloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\Jakinda\\Documents\\Python Scripts\\challenge2\\challenge2\\cloud\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     wc = WordCloud(background_color=\"white\",\n\u001b[0;32m      5\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2911\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2912\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2913\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\Jakinda\\\\Documents\\\\Python Scripts\\\\challenge2\\\\challenge2\\\\cloud'"
     ]
    }
   ],
   "source": [
    "#Creating wordcloud for positive sentiment\n",
    "create_wordcloud(CleanTweets_positive[\"score\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating wordcloud for negative sentiment\n",
    "create_wordcloud(CleanTweets_negative[\"score\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>score</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>positive</td>\n",
       "      <td>188</td>\n",
       "      <td>27</td>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>positive</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hearing say 's confident vaccines delivered li...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>92</td>\n",
       "      <td>14</td>\n",
       "      <td>Hearing say s confident vaccines delivered lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>positive</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria `` right '' grid tariffs regulatory re...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>positive</td>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "      <td>Austria  right  grid tariffs regulatory regime...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  polarity     score  \\\n",
       "0  Giving forth life becoming burden Kenya This m...  0.319444  positive   \n",
       "1  Today World Day Combat Restoring degraded land...  0.250000  positive   \n",
       "2  Hearing say 's confident vaccines delivered li...  0.500000  positive   \n",
       "3  Today World Day Combat Restoring degraded land...  0.250000  positive   \n",
       "4  Austria `` right '' grid tariffs regulatory re...  0.285714  positive   \n",
       "\n",
       "   text_len  text_word_count  \\\n",
       "0       188               27   \n",
       "1       146               22   \n",
       "2        92               14   \n",
       "3       146               22   \n",
       "4        82               13   \n",
       "\n",
       "                                               punct  \n",
       "0  Giving forth life becoming burden Kenya This m...  \n",
       "1  Today World Day Combat Restoring degraded land...  \n",
       "2  Hearing say s confident vaccines delivered lik...  \n",
       "3  Today World Day Combat Restoring degraded land...  \n",
       "4  Austria  right  grid tariffs regulatory regime...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing Punctuation\n",
    "def remove_punct(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0–9]+', '', text)\n",
    "    return text\n",
    "CleanTweets['punct'] = CleanTweets['clean_text'].apply(lambda x: remove_punct(x))\n",
    "CleanTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>score</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>punct</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>positive</td>\n",
       "      <td>188</td>\n",
       "      <td>27</td>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>[giving, forth, life, becoming, burden, kenya,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>positive</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hearing say 's confident vaccines delivered li...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>92</td>\n",
       "      <td>14</td>\n",
       "      <td>Hearing say s confident vaccines delivered lik...</td>\n",
       "      <td>[hearing, say, s, confident, vaccines, deliver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>positive</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria `` right '' grid tariffs regulatory re...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>positive</td>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "      <td>Austria  right  grid tariffs regulatory regime...</td>\n",
       "      <td>[austria, right, grid, tariffs, regulatory, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  polarity     score  \\\n",
       "0  Giving forth life becoming burden Kenya This m...  0.319444  positive   \n",
       "1  Today World Day Combat Restoring degraded land...  0.250000  positive   \n",
       "2  Hearing say 's confident vaccines delivered li...  0.500000  positive   \n",
       "3  Today World Day Combat Restoring degraded land...  0.250000  positive   \n",
       "4  Austria `` right '' grid tariffs regulatory re...  0.285714  positive   \n",
       "\n",
       "   text_len  text_word_count  \\\n",
       "0       188               27   \n",
       "1       146               22   \n",
       "2        92               14   \n",
       "3       146               22   \n",
       "4        82               13   \n",
       "\n",
       "                                               punct  \\\n",
       "0  Giving forth life becoming burden Kenya This m...   \n",
       "1  Today World Day Combat Restoring degraded land...   \n",
       "2  Hearing say s confident vaccines delivered lik...   \n",
       "3  Today World Day Combat Restoring degraded land...   \n",
       "4  Austria  right  grid tariffs regulatory regime...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [giving, forth, life, becoming, burden, kenya,...  \n",
       "1  [today, world, day, combat, restoring, degrade...  \n",
       "2  [hearing, say, s, confident, vaccines, deliver...  \n",
       "3  [today, world, day, combat, restoring, degrade...  \n",
       "4  [austria, right, grid, tariffs, regulatory, re...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Appliyng tokenization\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "CleanTweets['tokenized'] = CleanTweets['punct'].apply(lambda x: tokenization(x.lower()))\n",
    "CleanTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>score</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>punct</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>positive</td>\n",
       "      <td>188</td>\n",
       "      <td>27</td>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>[giving, forth, life, becoming, burden, kenya,...</td>\n",
       "      <td>[giving, forth, life, becoming, burden, kenya,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>positive</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hearing say 's confident vaccines delivered li...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>92</td>\n",
       "      <td>14</td>\n",
       "      <td>Hearing say s confident vaccines delivered lik...</td>\n",
       "      <td>[hearing, say, s, confident, vaccines, deliver...</td>\n",
       "      <td>[hearing, say, confident, vaccines, delivered,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>positive</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria `` right '' grid tariffs regulatory re...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>positive</td>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "      <td>Austria  right  grid tariffs regulatory regime...</td>\n",
       "      <td>[austria, right, grid, tariffs, regulatory, re...</td>\n",
       "      <td>[austria, right, grid, tariffs, regulatory, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  polarity     score  \\\n",
       "0  Giving forth life becoming burden Kenya This m...  0.319444  positive   \n",
       "1  Today World Day Combat Restoring degraded land...  0.250000  positive   \n",
       "2  Hearing say 's confident vaccines delivered li...  0.500000  positive   \n",
       "3  Today World Day Combat Restoring degraded land...  0.250000  positive   \n",
       "4  Austria `` right '' grid tariffs regulatory re...  0.285714  positive   \n",
       "\n",
       "   text_len  text_word_count  \\\n",
       "0       188               27   \n",
       "1       146               22   \n",
       "2        92               14   \n",
       "3       146               22   \n",
       "4        82               13   \n",
       "\n",
       "                                               punct  \\\n",
       "0  Giving forth life becoming burden Kenya This m...   \n",
       "1  Today World Day Combat Restoring degraded land...   \n",
       "2  Hearing say s confident vaccines delivered lik...   \n",
       "3  Today World Day Combat Restoring degraded land...   \n",
       "4  Austria  right  grid tariffs regulatory regime...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [giving, forth, life, becoming, burden, kenya,...   \n",
       "1  [today, world, day, combat, restoring, degrade...   \n",
       "2  [hearing, say, s, confident, vaccines, deliver...   \n",
       "3  [today, world, day, combat, restoring, degrade...   \n",
       "4  [austria, right, grid, tariffs, regulatory, re...   \n",
       "\n",
       "                                             nonstop  \n",
       "0  [giving, forth, life, becoming, burden, kenya,...  \n",
       "1  [today, world, day, combat, restoring, degrade...  \n",
       "2  [hearing, say, confident, vaccines, delivered,...  \n",
       "3  [today, world, day, combat, restoring, degrade...  \n",
       "4  [austria, right, grid, tariffs, regulatory, re...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing stopwords\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "    \n",
    "CleanTweets['nonstop'] = CleanTweets['tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "CleanTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>score</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>punct</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>positive</td>\n",
       "      <td>188</td>\n",
       "      <td>27</td>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>[giving, forth, life, becoming, burden, kenya,...</td>\n",
       "      <td>[giving, forth, life, becoming, burden, kenya,...</td>\n",
       "      <td>[give, forth, life, becom, burden, kenya, moth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>positive</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "      <td>[today, world, day, combat, restor, degrad, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hearing say 's confident vaccines delivered li...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>92</td>\n",
       "      <td>14</td>\n",
       "      <td>Hearing say s confident vaccines delivered lik...</td>\n",
       "      <td>[hearing, say, s, confident, vaccines, deliver...</td>\n",
       "      <td>[hearing, say, confident, vaccines, delivered,...</td>\n",
       "      <td>[hear, say, confid, vaccin, deliv, like, hear,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>positive</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "      <td>[today, world, day, combat, restor, degrad, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria `` right '' grid tariffs regulatory re...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>positive</td>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "      <td>Austria  right  grid tariffs regulatory regime...</td>\n",
       "      <td>[austria, right, grid, tariffs, regulatory, re...</td>\n",
       "      <td>[austria, right, grid, tariffs, regulatory, re...</td>\n",
       "      <td>[austria, right, grid, tariff, regulatori, reg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  polarity     score  \\\n",
       "0  Giving forth life becoming burden Kenya This m...  0.319444  positive   \n",
       "1  Today World Day Combat Restoring degraded land...  0.250000  positive   \n",
       "2  Hearing say 's confident vaccines delivered li...  0.500000  positive   \n",
       "3  Today World Day Combat Restoring degraded land...  0.250000  positive   \n",
       "4  Austria `` right '' grid tariffs regulatory re...  0.285714  positive   \n",
       "\n",
       "   text_len  text_word_count  \\\n",
       "0       188               27   \n",
       "1       146               22   \n",
       "2        92               14   \n",
       "3       146               22   \n",
       "4        82               13   \n",
       "\n",
       "                                               punct  \\\n",
       "0  Giving forth life becoming burden Kenya This m...   \n",
       "1  Today World Day Combat Restoring degraded land...   \n",
       "2  Hearing say s confident vaccines delivered lik...   \n",
       "3  Today World Day Combat Restoring degraded land...   \n",
       "4  Austria  right  grid tariffs regulatory regime...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [giving, forth, life, becoming, burden, kenya,...   \n",
       "1  [today, world, day, combat, restoring, degrade...   \n",
       "2  [hearing, say, s, confident, vaccines, deliver...   \n",
       "3  [today, world, day, combat, restoring, degrade...   \n",
       "4  [austria, right, grid, tariffs, regulatory, re...   \n",
       "\n",
       "                                             nonstop  \\\n",
       "0  [giving, forth, life, becoming, burden, kenya,...   \n",
       "1  [today, world, day, combat, restoring, degrade...   \n",
       "2  [hearing, say, confident, vaccines, delivered,...   \n",
       "3  [today, world, day, combat, restoring, degrade...   \n",
       "4  [austria, right, grid, tariffs, regulatory, re...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  [give, forth, life, becom, burden, kenya, moth...  \n",
       "1  [today, world, day, combat, restor, degrad, la...  \n",
       "2  [hear, say, confid, vaccin, deliv, like, hear,...  \n",
       "3  [today, world, day, combat, restor, degrad, la...  \n",
       "4  [austria, right, grid, tariff, regulatori, reg...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Appliyng Stemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "CleanTweets['stemmed'] = CleanTweets['nonstop'].apply(lambda x: stemming(x))\n",
    "CleanTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Text\n",
    "def clean_text(text):\n",
    "    text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n",
    "    text_rc = re.sub('[0-9]+', '', text_lc)\n",
    "    tokens = re.split('\\W+', text_rc)    # tokenization\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopword]  # remove stopwords and stemming\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>score</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>punct</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>positive</td>\n",
       "      <td>188</td>\n",
       "      <td>27</td>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>[giving, forth, life, becoming, burden, kenya,...</td>\n",
       "      <td>[giving, forth, life, becoming, burden, kenya,...</td>\n",
       "      <td>[give, forth, life, becom, burden, kenya, moth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>positive</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "      <td>[today, world, day, combat, restor, degrad, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hearing say 's confident vaccines delivered li...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>92</td>\n",
       "      <td>14</td>\n",
       "      <td>Hearing say s confident vaccines delivered lik...</td>\n",
       "      <td>[hearing, say, s, confident, vaccines, deliver...</td>\n",
       "      <td>[hearing, say, confident, vaccines, delivered,...</td>\n",
       "      <td>[hear, say, confid, vaccin, deliv, like, hear,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>positive</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "      <td>[today, world, day, combat, restoring, degrade...</td>\n",
       "      <td>[today, world, day, combat, restor, degrad, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria `` right '' grid tariffs regulatory re...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>positive</td>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "      <td>Austria  right  grid tariffs regulatory regime...</td>\n",
       "      <td>[austria, right, grid, tariffs, regulatory, re...</td>\n",
       "      <td>[austria, right, grid, tariffs, regulatory, re...</td>\n",
       "      <td>[austria, right, grid, tariff, regulatori, reg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  polarity     score  \\\n",
       "0  Giving forth life becoming burden Kenya This m...  0.319444  positive   \n",
       "1  Today World Day Combat Restoring degraded land...  0.250000  positive   \n",
       "2  Hearing say 's confident vaccines delivered li...  0.500000  positive   \n",
       "3  Today World Day Combat Restoring degraded land...  0.250000  positive   \n",
       "4  Austria `` right '' grid tariffs regulatory re...  0.285714  positive   \n",
       "\n",
       "   text_len  text_word_count  \\\n",
       "0       188               27   \n",
       "1       146               22   \n",
       "2        92               14   \n",
       "3       146               22   \n",
       "4        82               13   \n",
       "\n",
       "                                               punct  \\\n",
       "0  Giving forth life becoming burden Kenya This m...   \n",
       "1  Today World Day Combat Restoring degraded land...   \n",
       "2  Hearing say s confident vaccines delivered lik...   \n",
       "3  Today World Day Combat Restoring degraded land...   \n",
       "4  Austria  right  grid tariffs regulatory regime...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [giving, forth, life, becoming, burden, kenya,...   \n",
       "1  [today, world, day, combat, restoring, degrade...   \n",
       "2  [hearing, say, s, confident, vaccines, deliver...   \n",
       "3  [today, world, day, combat, restoring, degrade...   \n",
       "4  [austria, right, grid, tariffs, regulatory, re...   \n",
       "\n",
       "                                             nonstop  \\\n",
       "0  [giving, forth, life, becoming, burden, kenya,...   \n",
       "1  [today, world, day, combat, restoring, degrade...   \n",
       "2  [hearing, say, confident, vaccines, delivered,...   \n",
       "3  [today, world, day, combat, restoring, degrade...   \n",
       "4  [austria, right, grid, tariffs, regulatory, re...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  [give, forth, life, becom, burden, kenya, moth...  \n",
       "1  [today, world, day, combat, restor, degrad, la...  \n",
       "2  [hear, say, confid, vaccin, deliv, like, hear,...  \n",
       "3  [today, world, day, combat, restor, degrad, la...  \n",
       "4  [austria, right, grid, tariff, regulatori, reg...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleanTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3487 Number of reviews has 4004 words\n"
     ]
    }
   ],
   "source": [
    "#Appliyng Countvectorizer\n",
    "countVectorizer = CountVectorizer(analyzer=clean_text) \n",
    "countVector = countVectorizer.fit_transform(CleanTweets['clean_text'])\n",
    "print('{} Number of reviews has {} words'.format(countVector.shape[0], countVector.shape[1]))\n",
    "#print(countVectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aadi</th>\n",
       "      <th>aapanu</th>\n",
       "      <th>aapina</th>\n",
       "      <th>aarc</th>\n",
       "      <th>aath</th>\n",
       "      <th>aathi</th>\n",
       "      <th>aathu</th>\n",
       "      <th>aayana</th>\n",
       "      <th>...</th>\n",
       "      <th>zeroreli</th>\n",
       "      <th>zerowast</th>\n",
       "      <th>zerva</th>\n",
       "      <th>zimbabw</th>\n",
       "      <th>zindhabad</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooplankton</th>\n",
       "      <th>zvamunokoshesawo</th>\n",
       "      <th>zvimw</th>\n",
       "      <th>zvinhu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aadi  aapanu  aapina  aarc  aath  aathi  aathu  aayana  ...  \\\n",
       "0  0   0     0       0       0     0     0      0      0       0  ...   \n",
       "1  0   0     0       0       0     0     0      0      0       0  ...   \n",
       "2  0   0     0       0       0     0     0      0      0       0  ...   \n",
       "3  0   0     0       0       0     0     0      0      0       0  ...   \n",
       "4  0   0     0       0       0     0     0      0      0       0  ...   \n",
       "\n",
       "   zeroreli  zerowast  zerva  zimbabw  zindhabad  zone  zooplankton  \\\n",
       "0         0         0      0        0          0     0            0   \n",
       "1         0         0      0        0          0     0            0   \n",
       "2         0         0      0        0          0     0            0   \n",
       "3         0         0      0        0          0     0            0   \n",
       "4         0         0      0        0          0     0            0   \n",
       "\n",
       "   zvamunokoshesawo  zvimw  zvinhu  \n",
       "0                 0      0       0  \n",
       "1                 0      0       0  \n",
       "2                 0      0       0  \n",
       "3                 0      0       0  \n",
       "4                 0      0       0  \n",
       "\n",
       "[5 rows x 4004 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect_df = pd.DataFrame(countVector.toarray(), columns=countVectorizer.get_feature_names())\n",
    "count_vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kuda</th>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lo</th>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emiss</th>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oil</th>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt</th>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax</th>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "kuda     1082\n",
       "amp       860\n",
       "lo        648\n",
       "emiss     620\n",
       "oil       568\n",
       "gt        484\n",
       "right     440\n",
       "tax       420\n",
       "use       410\n",
       "neutral   400"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most Used Words\n",
    "count = pd.DataFrame(count_vect_df.sum())\n",
    "countdf = count.sort_values(0,ascending=False).head(20)\n",
    "countdf[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('carbon neutral', 394),\n",
       " ('gt gt', 364),\n",
       " ('selaput dara', 292),\n",
       " ('carbon tax', 214),\n",
       " ('box office', 202),\n",
       " ('ki kuda', 198),\n",
       " ('electoral reform', 192),\n",
       " ('new coal', 192),\n",
       " ('lambie voted', 190),\n",
       " ('voted medivac', 190),\n",
       " ('medivac carbon', 190),\n",
       " ('tax protecting', 190),\n",
       " ('protecting whistleblowers', 190),\n",
       " ('whistleblowers banning', 190),\n",
       " ('banning new', 190),\n",
       " ('coal mines', 190),\n",
       " ('mines protecting', 190),\n",
       " ('protecting barrier', 190),\n",
       " ('barrier reef', 190),\n",
       " ('reef senate', 190)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to ngram\n",
    "def get_top_n_gram(corpus,ngram_range,n=None):\n",
    "    vec = CountVectorizer(ngram_range=ngram_range,stop_words = 'english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "#n2_bigram\n",
    "n2_bigrams = get_top_n_gram(CleanTweets['clean_text'],(2,2),20)\n",
    "n2_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gt gt gt', 250),\n",
       " ('lambie voted medivac', 190),\n",
       " ('voted medivac carbon', 190),\n",
       " ('medivac carbon tax', 190),\n",
       " ('carbon tax protecting', 190),\n",
       " ('tax protecting whistleblowers', 190),\n",
       " ('protecting whistleblowers banning', 190),\n",
       " ('whistleblowers banning new', 190),\n",
       " ('banning new coal', 190),\n",
       " ('new coal mines', 190),\n",
       " ('coal mines protecting', 190),\n",
       " ('mines protecting barrier', 190),\n",
       " ('protecting barrier reef', 190),\n",
       " ('barrier reef senate', 190),\n",
       " ('reef senate electoral', 190),\n",
       " ('senate electoral reform', 190),\n",
       " ('electoral reform minerals', 190),\n",
       " ('reform minerals resource', 190),\n",
       " ('minerals resource rent', 190),\n",
       " ('resource rent tax', 190)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#n3_trigram\n",
    "n3_trigrams = get_top_n_gram(CleanTweets['clean_text'],(3,3),20)\n",
    "n3_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Challenge_ Day2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
